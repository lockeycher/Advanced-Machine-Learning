{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SciKit DSC540 HW4\n",
    "'''created by Casey Bennett 2018, www.CaseyBennett.com'''\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_selection import RFE, VarianceThreshold, SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression, mutual_info_classif, chi2\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer, scale\n",
    "\n",
    "#Handle annoying warnings\n",
    "import warnings, sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.ConvergenceWarning)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#\n",
    "# Global parameters\n",
    "#\n",
    "#####################\n",
    "\n",
    "target_idx=0                                        #Index of Target variable\n",
    "cross_val=1                                         #Control Switch for CV                                                                                                                                                                                           \n",
    "norm_target=0                                       #Normalize target switch\n",
    "norm_features=1                                     #Normalize target switch                                                                                                    \n",
    "binning=0                                           #Control Switch for Bin Target\n",
    "bin_cnt=2                                           #If bin target, this sets number of classes\n",
    "feat_select=1                                       #Control Switch for Feature Selection                                                                                        \n",
    "fs_type=4                                           #Feature Selection type (1=Stepwise Backwards Removal, 2=Wrapper Select, 3=Univariate Selection)\n",
    "lv_filter=0                                         #Control switch for low variance filter on features\n",
    "feat_start=1                                        #Start column of features\n",
    "k_cnt=5                                             #Number of 'Top k' best ranked features to select, only applies for fs_types 1 and 3\n",
    "\n",
    "#Set global model parameters\n",
    "rand_st=1                                           #Set Random State variable for randomizing splits on runs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#\n",
    "# Wrapper Feat Select Helper\n",
    "#\n",
    "##########################################\n",
    "\n",
    "#Recursive Function for searching thru feature space\n",
    "def feat_space_search(arr, curr_idx):\n",
    "    '''Setup currently as exhuastive search, but could be changed to use\n",
    "       greedy search, random search, genetic algorithms, etc. ... also\n",
    "       no regularization, so probably selects more features than necessary'''\n",
    "    global roll_idx, combo_ctr, best_score, sel_idx\n",
    "    \n",
    "    if curr_idx==feat_cnt:\n",
    "        #If end of feature array, roll thru combinations\n",
    "        roll_idx=roll_idx+1\n",
    "        print (\"Combos Searched so far:\", combo_ctr, \"Current Best Score:\", best_score)\n",
    "        for i in range(roll_idx, len(arr)):\n",
    "            arr[i]=0\n",
    "        if roll_idx<feat_cnt-1:\n",
    "            feat_space_search(arr, roll_idx+1)                                                                      #Recurse till end of rolls\n",
    "        \n",
    "    else:\n",
    "        #Else setup next feature combination and calc performance\n",
    "        arr[curr_idx]=1\n",
    "        data=data_np#_wrap                                                                                          #Temp array to hold data\n",
    "        temp_del=[i for i in range(len(arr)) if arr[i]==0]                                                          #Pick out features not in this combo, and remove\n",
    "        data = np.delete(data, temp_del, axis=1)\n",
    "        data_train, data_test, target_train, target_test = train_test_split(data, target_np, test_size=0.35)                \n",
    "\n",
    "        if binning==1:\n",
    "            if bin_cnt<=2:\n",
    "                scorers = {'Accuracy': 'accuracy', 'roc_auc': 'roc_auc'}\n",
    "                scores = cross_validate(clf, data_np, target_np, scoring=scorers, cv=5) \n",
    "                score = scores['test_roc_auc'].mean()                                                               #AUC\n",
    "            else:\n",
    "                sscorers = {'Accuracy': 'accuracy'}\n",
    "                scores = cross_validate(clf, data_np, target_np, scoring=scorers, cv=5) \n",
    "                score = scores['test_Accuracy'].mean()                                                              #Accuracy\n",
    "            print('Random Forest Acc/AUC:', curr_idx, feat_arr, len(data[0]), score)\n",
    "            if score>best_score:                                                                                    #Compare performance and update sel_idx and best_score, if needed\n",
    "                best_score=score\n",
    "                sel_idx=copy.deepcopy(arr) \n",
    "                \n",
    "        if binning==0:\n",
    "            scorers = {'Neg_MSE': 'neg_mean_squared_error', 'expl_var': 'explained_variance'}\n",
    "            scores = cross_validate(rgr, data, target_np, scoring=scorers, cv=5)    \n",
    "            score = np.asarray([math.sqrt(-x) for x in scores['test_Neg_MSE']]).mean()                              #RMSE\n",
    "            print('Random Forest RMSE:', curr_idx, feat_arr, len(data[0]), score)\n",
    "            if score<best_score:                                                                                    #Compare performance and update sel_idx and best_score, if needed\n",
    "                best_score=score\n",
    "                sel_idx=copy.deepcopy(arr) \n",
    "\n",
    "        #move to next feature index and recurse\n",
    "        combo_ctr+=1  \n",
    "        curr_idx+=1\n",
    "        feat_space_search(arr, curr_idx)                                                                            #Recurse till end of iteration for roll\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Class', 'fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
      "1599 1599\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "#\n",
    "# Load Data\n",
    "#\n",
    "#####################\n",
    "\n",
    "file1= csv.reader(open('WineQuality_Red.csv'), delimiter=',', quotechar='\"')\n",
    "\n",
    "#Read Header Line\n",
    "header=next(file1)            \n",
    "\n",
    "#Read data\n",
    "data=[]\n",
    "target=[]\n",
    "for row in file1:\n",
    "    #Load Target\n",
    "    if row[target_idx]=='':                         #If target is blank, skip row                       \n",
    "        continue\n",
    "    else:\n",
    "        target.append(float(row[target_idx]))       #If pre-binned class, change float to int\n",
    "\n",
    "    #Load row into temp array, cast columns  \n",
    "    temp=[]\n",
    "                 \n",
    "    for j in range(feat_start,len(header)):\n",
    "        if row[j]=='':\n",
    "            temp.append(float())\n",
    "        else:\n",
    "            temp.append(float(row[j]))\n",
    "\n",
    "    #Load temp into Data array\n",
    "    data.append(temp)\n",
    "  \n",
    "#Test Print\n",
    "print(header)\n",
    "print(len(target),len(data))\n",
    "print('\\n')\n",
    "\n",
    "data_np=np.asarray(data)\n",
    "target_np=np.asarray(target)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#\n",
    "# Preprocess data\n",
    "#\n",
    "##########################################\n",
    "\n",
    "if norm_target==1:\n",
    "    #Target normalization for continuous values\n",
    "    target_np=scale(target_np)\n",
    "\n",
    "if norm_features==1:\n",
    "    #Feature normalization for continuous values\n",
    "    data_np=scale(data_np)\n",
    "\n",
    "if binning==1:\n",
    "    #Discretize Target variable with KBinsDiscretizer\n",
    "    enc = KBinsDiscretizer(n_bins=[bin_cnt], encode='ordinal', strategy='quantile')                         #Strategy here is important, quantile creating equal bins, but kmeans prob being more valid \"clusters\"\n",
    "    target_np_bin = enc.fit_transform(target_np.reshape(-1,1))\n",
    "\n",
    "    #Get Bin min/max\n",
    "    temp=[[] for x in range(bin_cnt+1)]\n",
    "    for i in range(len(target_np)):\n",
    "        for j in range(bin_cnt):\n",
    "            if target_np_bin[i]==j:\n",
    "                temp[j].append(target_np[i])\n",
    "\n",
    "    for j in range(bin_cnt):\n",
    "        print('Bin', j, ':', min(temp[j]), max(temp[j]), len(temp[j]))\n",
    "    print('\\n')\n",
    "\n",
    "    #Convert Target array back to correct shape\n",
    "    target_np=np.ravel(target_np_bin)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--FEATURE SELECTION ON-- \n",
      "\n",
      "Random Forest RMSE: 0 [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 1 0.8838595069304984\n",
      "Random Forest RMSE: 1 [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0] 2 0.7583279027750782\n",
      "Random Forest RMSE: 2 [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0] 3 0.7601747499953804\n",
      "Random Forest RMSE: 3 [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0] 4 0.7614131615860809\n",
      "Random Forest RMSE: 4 [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0] 5 0.7529034747655474\n",
      "Random Forest RMSE: 5 [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] 6 0.753997337443167\n",
      "Random Forest RMSE: 6 [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0] 7 0.7351744756641166\n",
      "Random Forest RMSE: 7 [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0] 8 0.7068355888893423\n",
      "Random Forest RMSE: 8 [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0] 9 0.7055446816953973\n",
      "Random Forest RMSE: 9 [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0] 10 0.6890040034487401\n",
      "Random Forest RMSE: 10 [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] 11 0.6617118403123001\n",
      "Combos Searched so far: 11 Current Best Score: 0.6617118403123001\n",
      "Random Forest RMSE: 2 [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0] 2 0.8203771387463258\n",
      "Random Forest RMSE: 3 [1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0] 3 0.8207528834326021\n",
      "Random Forest RMSE: 4 [1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0] 4 0.8004295942454298\n",
      "Random Forest RMSE: 5 [1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0] 5 0.8022481475262786\n",
      "Random Forest RMSE: 6 [1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0] 6 0.769845144774307\n",
      "Random Forest RMSE: 7 [1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0] 7 0.7282450885019678\n",
      "Random Forest RMSE: 8 [1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0] 8 0.727032572631073\n",
      "Random Forest RMSE: 9 [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0] 9 0.702293210221311\n",
      "Random Forest RMSE: 10 [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1] 10 0.6775347079231991\n",
      "Combos Searched so far: 20 Current Best Score: 0.6617118403123001\n",
      "Random Forest RMSE: 3 [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0] 2 0.8829611345289585\n",
      "Random Forest RMSE: 4 [1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0] 3 0.8580816794975921\n",
      "Random Forest RMSE: 5 [1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0] 4 0.8542535470088687\n",
      "Random Forest RMSE: 6 [1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0] 5 0.7942189562588532\n",
      "Random Forest RMSE: 7 [1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0] 6 0.7396709989512227\n",
      "Random Forest RMSE: 8 [1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0] 7 0.7404787675572193\n",
      "Random Forest RMSE: 9 [1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0] 8 0.7094012560100013\n",
      "Random Forest RMSE: 10 [1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1] 9 0.6811790291066833\n",
      "Combos Searched so far: 28 Current Best Score: 0.6617118403123001\n",
      "Random Forest RMSE: 4 [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0] 2 0.8586392148957323\n",
      "Random Forest RMSE: 5 [1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0] 3 0.8541796216559983\n",
      "Random Forest RMSE: 6 [1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0] 4 0.7940130229422977\n",
      "Random Forest RMSE: 7 [1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0] 5 0.7543843847217387\n",
      "Random Forest RMSE: 8 [1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0] 6 0.7530857009150389\n",
      "Random Forest RMSE: 9 [1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0] 7 0.7260869738793252\n",
      "Random Forest RMSE: 10 [1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1] 8 0.6834015014199848\n",
      "Combos Searched so far: 35 Current Best Score: 0.6617118403123001\n",
      "Random Forest RMSE: 5 [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0] 2 0.874384625605825\n",
      "Random Forest RMSE: 6 [1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0] 3 0.8016307826826674\n",
      "Random Forest RMSE: 7 [1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0] 4 0.7574052537673538\n",
      "Random Forest RMSE: 8 [1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0] 5 0.7548889137034545\n",
      "Random Forest RMSE: 9 [1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0] 6 0.7418643866274692\n",
      "Random Forest RMSE: 10 [1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1] 7 0.6960956126090193\n",
      "Combos Searched so far: 41 Current Best Score: 0.6617118403123001\n",
      "Random Forest RMSE: 6 [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0] 2 0.8100370813176815\n",
      "Random Forest RMSE: 7 [1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0] 3 0.7636719650867922\n",
      "Random Forest RMSE: 8 [1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0] 4 0.7621082752532629\n",
      "Random Forest RMSE: 9 [1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0] 5 0.7453521101097268\n",
      "Random Forest RMSE: 10 [1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1] 6 0.6982649816479924\n",
      "Combos Searched so far: 46 Current Best Score: 0.6617118403123001\n",
      "Random Forest RMSE: 7 [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0] 2 0.7681351218681289\n",
      "Random Forest RMSE: 8 [1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0] 3 0.7696332726188043\n",
      "Random Forest RMSE: 9 [1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0] 4 0.7581785728471915\n",
      "Random Forest RMSE: 10 [1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1] 5 0.7027999197487682\n",
      "Combos Searched so far: 50 Current Best Score: 0.6617118403123001\n",
      "Random Forest RMSE: 8 [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0] 2 0.8715617712746674\n",
      "Random Forest RMSE: 9 [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0] 3 0.8339222878322499\n",
      "Random Forest RMSE: 10 [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1] 4 0.7039779017675163\n",
      "Combos Searched so far: 53 Current Best Score: 0.6617118403123001\n",
      "Random Forest RMSE: 9 [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0] 2 0.835471908519413\n",
      "Random Forest RMSE: 10 [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1] 3 0.7011803092754061\n",
      "Combos Searched so far: 55 Current Best Score: 0.6617118403123001\n",
      "Random Forest RMSE: 10 [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1] 2 0.7106557857694622\n",
      "Combos Searched so far: 56 Current Best Score: 0.6617118403123001\n",
      "Random Forest RMSE: 1 [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0] 1 0.7538326040995666\n",
      "Random Forest RMSE: 2 [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0] 2 0.7560321514148194\n",
      "Random Forest RMSE: 3 [0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0] 3 0.7569781284978147\n",
      "Random Forest RMSE: 4 [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0] 4 0.7493331064167427\n",
      "Random Forest RMSE: 5 [0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0] 5 0.7497147266622797\n",
      "Random Forest RMSE: 6 [0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0] 6 0.7331738824142411\n",
      "Random Forest RMSE: 7 [0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0] 7 0.7219971078002652\n",
      "Random Forest RMSE: 8 [0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0] 8 0.7222819206159425\n",
      "Random Forest RMSE: 9 [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0] 9 0.7033977043743611\n",
      "Random Forest RMSE: 10 [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] 10 0.6600597802993462\n",
      "Combos Searched so far: 66 Current Best Score: 0.6600597802993462\n",
      "Random Forest RMSE: 3 [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0] 2 0.7540506097425033\n",
      "Random Forest RMSE: 4 [0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0] 3 0.7482530805231777\n",
      "Random Forest RMSE: 5 [0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0] 4 0.7470692910930536\n",
      "Random Forest RMSE: 6 [0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0] 5 0.7339959775462543\n",
      "Random Forest RMSE: 7 [0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0] 6 0.7321049032491687\n",
      "Random Forest RMSE: 8 [0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0] 7 0.728424276308749\n",
      "Random Forest RMSE: 9 [0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0] 8 0.7114632800807297\n",
      "Random Forest RMSE: 10 [0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1] 9 0.6596825116948701\n",
      "Combos Searched so far: 74 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 4 [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0] 2 0.7468821592874682\n",
      "Random Forest RMSE: 5 [0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0] 3 0.7469929954795966\n",
      "Random Forest RMSE: 6 [0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0] 4 0.734935812189673\n",
      "Random Forest RMSE: 7 [0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0] 5 0.736917706028787\n",
      "Random Forest RMSE: 8 [0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0] 6 0.7325255399890824\n",
      "Random Forest RMSE: 9 [0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0] 7 0.7173527448970884\n",
      "Random Forest RMSE: 10 [0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1] 8 0.6605283079973708\n",
      "Combos Searched so far: 81 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 5 [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0] 2 0.7531492722838389\n",
      "Random Forest RMSE: 6 [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0] 3 0.7395713792236609\n",
      "Random Forest RMSE: 7 [0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0] 4 0.7392120076586244\n",
      "Random Forest RMSE: 8 [0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0] 5 0.7371433236144551\n",
      "Random Forest RMSE: 9 [0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0] 6 0.7344814734898111\n",
      "Random Forest RMSE: 10 [0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1] 7 0.6699379020785943\n",
      "Combos Searched so far: 87 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 6 [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0] 2 0.74177180600301\n",
      "Random Forest RMSE: 7 [0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0] 3 0.7388454666493147\n",
      "Random Forest RMSE: 8 [0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0] 4 0.7394132308598607\n",
      "Random Forest RMSE: 9 [0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0] 5 0.7362217091206302\n",
      "Random Forest RMSE: 10 [0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1] 6 0.6715171747968528\n",
      "Combos Searched so far: 92 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 7 [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0] 2 0.7513839192973071\n",
      "Random Forest RMSE: 8 [0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0] 3 0.754080553758096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE: 9 [0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0] 4 0.7557081294835408\n",
      "Random Forest RMSE: 10 [0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1] 5 0.6780720787067034\n",
      "Combos Searched so far: 96 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 8 [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0] 2 0.7537696358599136\n",
      "Random Forest RMSE: 9 [0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0] 3 0.7549904805626544\n",
      "Random Forest RMSE: 10 [0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1] 4 0.676474690563204\n",
      "Combos Searched so far: 99 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 9 [0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0] 2 0.7548117487171598\n",
      "Random Forest RMSE: 10 [0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1] 3 0.6765905004226405\n",
      "Combos Searched so far: 101 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 10 [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1] 2 0.6765697591042016\n",
      "Combos Searched so far: 102 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 2 [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0] 1 0.8186783832393199\n",
      "Random Forest RMSE: 3 [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0] 2 0.8191765044993975\n",
      "Random Forest RMSE: 4 [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0] 3 0.797974045944499\n",
      "Random Forest RMSE: 5 [0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0] 4 0.8011226706025136\n",
      "Random Forest RMSE: 6 [0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0] 5 0.7709077242300015\n",
      "Random Forest RMSE: 7 [0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0] 6 0.7410683156193942\n",
      "Random Forest RMSE: 8 [0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0] 7 0.7424061702754081\n",
      "Random Forest RMSE: 9 [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0] 8 0.7159399345480557\n",
      "Random Forest RMSE: 10 [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1] 9 0.6772096475411569\n",
      "Combos Searched so far: 111 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 4 [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0] 2 0.7978499376317741\n",
      "Random Forest RMSE: 5 [0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0] 3 0.8001742017012855\n",
      "Random Forest RMSE: 6 [0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0] 4 0.7699767704928705\n",
      "Random Forest RMSE: 7 [0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0] 5 0.7443011063703195\n",
      "Random Forest RMSE: 8 [0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0] 6 0.7443233723796815\n",
      "Random Forest RMSE: 9 [0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0] 7 0.7226782005969381\n",
      "Random Forest RMSE: 10 [0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1] 8 0.6780042827472539\n",
      "Combos Searched so far: 118 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 5 [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0] 2 0.822262986569306\n",
      "Random Forest RMSE: 6 [0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0] 3 0.7820784520073568\n",
      "Random Forest RMSE: 7 [0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0] 4 0.7523001840765312\n",
      "Random Forest RMSE: 8 [0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0] 5 0.7564616780947595\n",
      "Random Forest RMSE: 9 [0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0] 6 0.7545981473042482\n",
      "Random Forest RMSE: 10 [0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1] 7 0.6922719372838302\n",
      "Combos Searched so far: 124 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 6 [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0] 2 0.792595562262444\n",
      "Random Forest RMSE: 7 [0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0] 3 0.7617796491123174\n",
      "Random Forest RMSE: 8 [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0] 4 0.762987815632447\n",
      "Random Forest RMSE: 9 [0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0] 5 0.7587714909907921\n",
      "Random Forest RMSE: 10 [0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1] 6 0.6964329471095506\n",
      "Combos Searched so far: 129 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 7 [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0] 2 0.7816254115590368\n",
      "Random Forest RMSE: 8 [0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0] 3 0.7861854597013836\n",
      "Random Forest RMSE: 9 [0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0] 4 0.7820736955057896\n",
      "Random Forest RMSE: 10 [0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1] 5 0.7043678873887073\n",
      "Combos Searched so far: 133 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 8 [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0] 2 0.8087367874678151\n",
      "Random Forest RMSE: 9 [0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0] 3 0.8066756152072992\n",
      "Random Forest RMSE: 10 [0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1] 4 0.7013773878542227\n",
      "Combos Searched so far: 136 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 9 [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0] 2 0.8161164745702205\n",
      "Random Forest RMSE: 10 [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1] 3 0.7011521841615675\n",
      "Combos Searched so far: 138 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 10 [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1] 2 0.7107091881132135\n",
      "Combos Searched so far: 139 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 3 [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0] 1 0.9076152183272997\n",
      "Random Forest RMSE: 4 [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0] 2 0.8829260190777083\n",
      "Random Forest RMSE: 5 [0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0] 3 0.8404242121301045\n",
      "Random Forest RMSE: 6 [0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0] 4 0.8011388786668757\n",
      "Random Forest RMSE: 7 [0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0] 5 0.8101151572721772\n",
      "Random Forest RMSE: 8 [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0] 6 0.7852429175473084\n",
      "Random Forest RMSE: 9 [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0] 7 0.7474618937202371\n",
      "Random Forest RMSE: 10 [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1] 8 0.68061114389565\n",
      "Combos Searched so far: 147 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 5 [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0] 2 0.8713391940280377\n",
      "Random Forest RMSE: 6 [0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0] 3 0.8067241206025709\n",
      "Random Forest RMSE: 7 [0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0] 4 0.8138739845061339\n",
      "Random Forest RMSE: 8 [0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0] 5 0.7969518206275509\n",
      "Random Forest RMSE: 9 [0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0] 6 0.7846314589668405\n",
      "Random Forest RMSE: 10 [0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1] 7 0.6972932971220799\n",
      "Combos Searched so far: 153 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 6 [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0] 2 0.8125744487157165\n",
      "Random Forest RMSE: 7 [0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0] 3 0.811566832871456\n",
      "Random Forest RMSE: 8 [0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0] 4 0.7997299986492667\n",
      "Random Forest RMSE: 9 [0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0] 5 0.785142012481416\n",
      "Random Forest RMSE: 10 [0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1] 6 0.7006916197580911\n",
      "Combos Searched so far: 158 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 7 [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0] 2 0.8751402169385563\n",
      "Random Forest RMSE: 8 [0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0] 3 0.8622716728882647\n",
      "Random Forest RMSE: 9 [0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0] 4 0.8214059536248616\n",
      "Random Forest RMSE: 10 [0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1] 5 0.7056837292441713\n",
      "Combos Searched so far: 162 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 8 [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0] 2 0.9073945212483376\n",
      "Random Forest RMSE: 9 [0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0] 3 0.8332151451548404\n",
      "Random Forest RMSE: 10 [0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1] 4 0.7019287977755506\n",
      "Combos Searched so far: 165 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 9 [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0] 2 0.8331341343617638\n",
      "Random Forest RMSE: 10 [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1] 3 0.7087132257964754\n",
      "Combos Searched so far: 167 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 10 [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1] 2 0.7263926297855093\n",
      "Combos Searched so far: 168 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 4 [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0] 1 0.8649212110631461\n",
      "Random Forest RMSE: 5 [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0] 2 0.8349723387275179\n",
      "Random Forest RMSE: 6 [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0] 3 0.8013507888552243\n",
      "Random Forest RMSE: 7 [0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0] 4 0.8126253377986401\n",
      "Random Forest RMSE: 8 [0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0] 5 0.7931973596645975\n",
      "Random Forest RMSE: 9 [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0] 6 0.7546819029780536\n",
      "Random Forest RMSE: 10 [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1] 7 0.6814297623253202\n",
      "Combos Searched so far: 175 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 6 [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0] 2 0.8072569355713345\n",
      "Random Forest RMSE: 7 [0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0] 3 0.8151577640191668\n",
      "Random Forest RMSE: 8 [0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0] 4 0.8014190908899014\n",
      "Random Forest RMSE: 9 [0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0] 5 0.7565720181397664\n",
      "Random Forest RMSE: 10 [0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1] 6 0.6858156745508304\n",
      "Combos Searched so far: 180 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 7 [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0] 2 0.8618361340401217\n",
      "Random Forest RMSE: 8 [0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0] 3 0.8387249121554513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE: 9 [0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0] 4 0.7841692116083575\n",
      "Random Forest RMSE: 10 [0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1] 5 0.6927013049520467\n",
      "Combos Searched so far: 184 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 8 [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0] 2 0.8475574819530334\n",
      "Random Forest RMSE: 9 [0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0] 3 0.7907309330961789\n",
      "Random Forest RMSE: 10 [0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1] 4 0.6906594587606218\n",
      "Combos Searched so far: 187 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 9 [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0] 2 0.7915577488358879\n",
      "Random Forest RMSE: 10 [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1] 3 0.6988928844453153\n",
      "Combos Searched so far: 189 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 10 [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1] 2 0.7265796229890172\n",
      "Combos Searched so far: 190 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 5 [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0] 1 0.8611320879579424\n",
      "Random Forest RMSE: 6 [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0] 2 0.807460176968571\n",
      "Random Forest RMSE: 7 [0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0] 3 0.8187247919466685\n",
      "Random Forest RMSE: 8 [0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0] 4 0.8015065653180592\n",
      "Random Forest RMSE: 9 [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0] 5 0.7937767457789369\n",
      "Random Forest RMSE: 10 [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1] 6 0.6966189562023601\n",
      "Combos Searched so far: 196 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 7 [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0] 2 0.8612185060230644\n",
      "Random Forest RMSE: 8 [0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0] 3 0.8445622705231448\n",
      "Random Forest RMSE: 9 [0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0] 4 0.8192247045043665\n",
      "Random Forest RMSE: 10 [0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1] 5 0.7059681585702139\n",
      "Combos Searched so far: 200 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 8 [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0] 2 0.8629419246109047\n",
      "Random Forest RMSE: 9 [0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0] 3 0.8317628590158666\n",
      "Random Forest RMSE: 10 [0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1] 4 0.7031624525091825\n",
      "Combos Searched so far: 203 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 9 [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0] 2 0.8335026058224049\n",
      "Random Forest RMSE: 10 [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1] 3 0.7107436777272368\n",
      "Combos Searched so far: 205 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 10 [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1] 2 0.7280092623337217\n",
      "Combos Searched so far: 206 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 6 [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0] 1 0.8134562550244077\n",
      "Random Forest RMSE: 7 [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0] 2 0.8192998577385024\n",
      "Random Forest RMSE: 8 [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0] 3 0.8088558557664941\n",
      "Random Forest RMSE: 9 [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0] 4 0.7963211321729055\n",
      "Random Forest RMSE: 10 [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1] 5 0.6992202606421241\n",
      "Combos Searched so far: 211 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 8 [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0] 2 0.8125526366310375\n",
      "Random Forest RMSE: 9 [0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0] 3 0.7989843703748963\n",
      "Random Forest RMSE: 10 [0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1] 4 0.6967078236041512\n",
      "Combos Searched so far: 214 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 9 [0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0] 2 0.7998538283255682\n",
      "Random Forest RMSE: 10 [0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1] 3 0.7037102108211573\n",
      "Combos Searched so far: 216 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 10 [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1] 2 0.721101125226128\n",
      "Combos Searched so far: 217 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 7 [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0] 1 0.8742397081242681\n",
      "Random Forest RMSE: 8 [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0] 2 0.8628520153520283\n",
      "Random Forest RMSE: 9 [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0] 3 0.8256295440708253\n",
      "Random Forest RMSE: 10 [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1] 4 0.7048553611122099\n",
      "Combos Searched so far: 221 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 9 [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0] 2 0.8206561558931345\n",
      "Random Forest RMSE: 10 [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1] 3 0.7093253618489893\n",
      "Combos Searched so far: 223 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 10 [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1] 2 0.7238280165894336\n",
      "Combos Searched so far: 224 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 8 [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0] 1 0.9143596635807896\n",
      "Random Forest RMSE: 9 [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0] 2 0.8309963143468039\n",
      "Random Forest RMSE: 10 [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1] 3 0.7015127857729755\n",
      "Combos Searched so far: 227 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 10 [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1] 2 0.7127634244764022\n",
      "Combos Searched so far: 228 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 9 [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0] 1 0.8328069917134858\n",
      "Random Forest RMSE: 10 [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1] 2 0.7074484724429647\n",
      "Combos Searched so far: 230 Current Best Score: 0.6596825116948701\n",
      "Random Forest RMSE: 10 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1] 1 0.7266641580854134\n",
      "Combos Searched so far: 231 Current Best Score: 0.6596825116948701\n",
      "# of Feature Combos Tested: 231\n",
      "0.6596825116948701 [0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1] 11\n",
      "Wrapper Feat Sel Runtime: 94.6967499256134\n",
      "Selected ['volatile acidity', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
      "Features (total/selected): 11 9\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "#\n",
    "# Feature Selection\n",
    "#\n",
    "##########################################\n",
    "\n",
    "#Low Variance Filter\n",
    "if lv_filter==1:\n",
    "    print('--LOW VARIANCE FILTER ON--', '\\n')\n",
    "    \n",
    "    #LV Threshold\n",
    "    sel = VarianceThreshold(threshold=0.5)                                      #Removes any feature with less than 20% variance\n",
    "    fit_mod=sel.fit(data_np)\n",
    "    fitted=sel.transform(data_np)\n",
    "    sel_idx=fit_mod.get_support()\n",
    "\n",
    "    #Get lists of selected and non-selected features (names and indexes)\n",
    "    temp=[]\n",
    "    temp_idx=[]\n",
    "    temp_del=[]\n",
    "    for i in range(len(data_np[0])):\n",
    "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
    "            temp.append(header[i+feat_start])\n",
    "            temp_idx.append(i)\n",
    "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
    "            temp_del.append(i)\n",
    "\n",
    "    print('Selected', temp)\n",
    "    print('Features (total, selected):', len(data_np[0]), len(temp))\n",
    "    print('\\n')\n",
    "\n",
    "    #Filter selected columns from original dataset\n",
    "    header = header[0:feat_start]\n",
    "    for field in temp:\n",
    "        header.append(field)\n",
    "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
    "\n",
    "\n",
    "#Feature Selection\n",
    "if feat_select==1:\n",
    "    '''Three steps:\n",
    "       1) Run Feature Selection\n",
    "       2) Get lists of selected and non-selected features\n",
    "       3) Filter columns from original dataset\n",
    "       '''\n",
    "    \n",
    "    print('--FEATURE SELECTION ON--', '\\n')\n",
    "    \n",
    "    ##1) Run Feature Selection #######\n",
    "    if fs_type==1:\n",
    "        #Stepwise Recursive Backwards Feature removal\n",
    "        if binning==1:\n",
    "            clf = RandomForestClassifier(n_estimators=200, max_depth=None, min_samples_split=3, criterion='entropy', random_state=rand_st)\n",
    "            sel = RFE(clf, n_features_to_select=k_cnt, step=.1)\n",
    "            print('Stepwise Recursive Backwards - Random Forest: ')\n",
    "        if binning==0:\n",
    "            rgr = RandomForestRegressor(n_estimators=500, max_depth=None, min_samples_split=3, criterion='mse', random_state=rand_st)\n",
    "            sel = RFE(rgr, n_features_to_select=k_cnt, step=.1)\n",
    "            print('Stepwise Recursive Backwards - Random Forest: ')\n",
    "            \n",
    "        fit_mod=sel.fit(data_np, target_np)\n",
    "        print(sel.ranking_)\n",
    "        sel_idx=fit_mod.get_support()      \n",
    "\n",
    "    if fs_type==2:\n",
    "        #Wrapper Select via model\n",
    "        if binning==1:\n",
    "            clf = '''Unused in this homework'''\n",
    "            sel = SelectFromModel(clf, prefit=False, threshold='mean', max_features=None)                                                           #to select only based on max_features, set to integer value and set threshold=-np.inf\n",
    "            print ('Wrapper Select: ')\n",
    "        if binning==0:\n",
    "            rgr = SVR(kernel='linear', gamma=0.1, C=1.0)\n",
    "            sel = SelectFromModel(rgr, prefit=False, threshold='mean', max_features=None)\n",
    "            print ('Wrapper Select: ')\n",
    "            \n",
    "        fit_mod=sel.fit(data_np, target_np)    \n",
    "        sel_idx=fit_mod.get_support()\n",
    "\n",
    "    if fs_type==3:\n",
    "        if binning==1:                                                              ######Only work if the Target is binned###########\n",
    "            #Univariate Feature Selection - Chi-squared\n",
    "            sel=SelectKBest(chi2, k=k_cnt)\n",
    "            fit_mod=sel.fit(data_np, target_np)                                         #will throw error if any negative values in features, so turn off feature normalization, or switch to mutual_info_classif\n",
    "            print ('Univariate Feature Selection - Chi2: ')\n",
    "            sel_idx=fit_mod.get_support()\n",
    "\n",
    "        if binning==0:                                                              ######Only work if the Target is continuous###########\n",
    "            #Univariate Feature Selection - Mutual Info Regression\n",
    "            sel=SelectKBest(mutual_info_regression, k=k_cnt)\n",
    "            fit_mod=sel.fit(data_np, target_np)\n",
    "            print ('Univariate Feature Selection - Mutual Info: ')\n",
    "            sel_idx=fit_mod.get_support()\n",
    "\n",
    "        #Print ranked variables out sorted\n",
    "        temp=[]\n",
    "        scores=fit_mod.scores_\n",
    "        for i in range(feat_start, len(header)):            \n",
    "            temp.append([header[i], float(scores[i-feat_start])])\n",
    "\n",
    "        print('Ranked Features')\n",
    "        temp_sort=sorted(temp, key=itemgetter(1), reverse=True)\n",
    "        for i in range(len(temp_sort)):\n",
    "            print(i, temp_sort[i][0], ':', temp_sort[i][1])\n",
    "        print('\\n')\n",
    "\n",
    "    if fs_type==4:\n",
    "        #Full-blown Wrapper Select (from any kind of ML model)        \n",
    "        if binning==1:                                                              ######Only work if the Target is binned###########\n",
    "            start_ts=time.time()\n",
    "            sel_idx=[]                                                                                      #Empty array to hold optimal selected feature set\n",
    "            best_score=0                                                                                    #For classification compare Accuracy or AUC, higher is better, so start with 0\n",
    "            feat_cnt=len(data_np[0])\n",
    "            #Create Wrapper model\n",
    "            clf = '''Unused in this homework'''                                 #This could be any kind of classifier model\n",
    "      \n",
    "        if binning==0:                                                              ######Only work if the Target is continuous###########\n",
    "            start_ts=time.time()\n",
    "            sel_idx=[]                                                                                      #Empty array to hold optimal selected feature set\n",
    "            best_score=sys.float_info.max                                                                   #For regression compare RMSE, lower is better, so start with max sys float value\n",
    "            feat_cnt=len(data_np[0])\n",
    "            #Create Wrapper model\n",
    "            rgr = SVR(kernel='linear', gamma=0.1, C=1.0)                    #This could be any kind of regressor model         \n",
    "        \n",
    "        #Loop thru feature sets\n",
    "        roll_idx=0\n",
    "        combo_ctr=0\n",
    "        feat_arr=[0 for col in range(feat_cnt)]                                         #Initialize feature array\n",
    "        for idx in range(feat_cnt):\n",
    "            roll_idx=idx\n",
    "            feat_space_search(feat_arr, idx)                                           #Recurse\n",
    "            feat_arr=[0 for col in range(feat_cnt)]                                     #Reset feature array after each iteration\n",
    "        \n",
    "        print('# of Feature Combos Tested:', combo_ctr)\n",
    "        print(best_score, sel_idx, len(data_np[0]))\n",
    "        print(\"Wrapper Feat Sel Runtime:\", time.time()-start_ts)\n",
    "\n",
    "    ##2) Get lists of selected and non-selected features (names and indexes) #######\n",
    "    temp=[]\n",
    "    temp_idx=[]\n",
    "    temp_del=[]\n",
    "    for i in range(len(data_np[0])):\n",
    "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
    "            temp.append(header[i+feat_start])\n",
    "            temp_idx.append(i)\n",
    "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
    "            temp_del.append(i)\n",
    "    print('Selected', temp)\n",
    "    print('Features (total/selected):', len(data_np[0]), len(temp))\n",
    "    print('\\n')\n",
    "            \n",
    "                \n",
    "    ##3) Filter selected columns from original dataset #########\n",
    "    header = header[0:feat_start]\n",
    "    for field in temp:\n",
    "        header.append(field)\n",
    "    data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--ML Model Output-- \n",
      "\n",
      "SVM RMSE:: 0.66 (+/- 0.02)\n",
      "SVM Expl Var: 0.30 (+/- 0.18)\n",
      "CV Runtime: 0.692650318145752\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "#\n",
    "# Train SciKit Models\n",
    "#\n",
    "##########################################\n",
    "\n",
    "print('--ML Model Output--', '\\n')\n",
    "\n",
    "#Test/Train split\n",
    "data_train, data_test, target_train, target_test = train_test_split(data_np, target_np, test_size=0.35)\n",
    "\n",
    "####Regressors####\n",
    "if binning==0 and cross_val==0:\n",
    "    #SciKit\n",
    "    '''Test/Train split unused in this homework, skip down to CV section'''\n",
    " \n",
    "\n",
    "                                                                                                                          \n",
    "\n",
    "####Cross-Val Regressors####\n",
    "if binning==0 and cross_val==1:\n",
    "    #Setup Crossval regression scorers\n",
    "    scorers = {'Neg_MSE': 'neg_mean_squared_error', 'expl_var': 'explained_variance'} \n",
    "    \n",
    "    #SciKit SVM - Cross Val\n",
    "    start_ts=time.time()\n",
    "    rgr=SVR(kernel='linear', gamma=0.1, C=1.0)\n",
    "    scores=cross_validate(rgr, data_np, target_np, scoring=scorers, cv=5)                                                                                                  \n",
    "\n",
    "    scores_RMSE = np.asarray([math.sqrt(-x) for x in scores['test_Neg_MSE']])                                       #Turns negative MSE scores into RMSE\n",
    "    scores_Expl_Var = scores['test_expl_var']\n",
    "    print(\"SVM RMSE:: %0.2f (+/- %0.2f)\" % ((scores_RMSE.mean()), (scores_RMSE.std() * 2)))\n",
    "    print(\"SVM Expl Var: %0.2f (+/- %0.2f)\" % ((scores_Expl_Var.mean()), (scores_Expl_Var.std() * 2)))\n",
    "    print(\"CV Runtime:\", time.time()-start_ts)\n",
    "\n",
    "\n",
    "    #SciKit LDA - Cross Val\n",
    "    '''Replace comment HERE''' \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
